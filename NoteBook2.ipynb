{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "i = 0\n",
    "fig = plt.figure(1, (30, 30))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(7, 3),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.2,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "\n",
    "print(\"Total images :\" , len(images))\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)    \n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        ax = grid[i]\n",
    "        ax.imshow(img)\n",
    "        i = i +1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "#print(ret)\n",
    "#print(corners)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above cell ran sucessfully, you should now have objpoints and imgpoints needed for camera calibration. Run the cell below to calibrate, calculate distortion coefficients, and test undistortion on an image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = cv2.imread('camera_cal/test_image.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('camera_cal/test_undist.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_pickle.p\", \"wb\" ) )\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#import cv2\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "def carmera_parameters():\n",
    "    # Read in the saved camera matrix and distortion coefficients\n",
    "    # These are the arrays you calculated using cv2.calibrateCamera()\n",
    "    dist_pickle = pickle.load( open( \"camera_cal/wide_dist_pickle.p\", \"rb\" ) )\n",
    "    mtx = dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "    return mtx,dist\n",
    "\n",
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    # 1) Undistort using mtx and dist.\n",
    "    undis = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # 2) Convert to grayscale\n",
    "    #plt.figure()\n",
    "    #plt.imshow(undis)\n",
    "    # 3) Find the chessboard corners\n",
    "    offset=10\n",
    "    \n",
    "    src_bottom_left = [260,680]\n",
    "    src_bottom_right = [1040,680]\n",
    "    src_top_left = [581,460]\n",
    "    src_top_right = [700,460]\n",
    "    \n",
    "    destination_bottom_left = [100,700]\n",
    "    destination_bottom_right = [1000,700]\n",
    "    destination_top_left = [100,50]\n",
    "    destination_top_right = [1000,50]\n",
    "    \n",
    "    #src = np.float32([corners[0],corners[nx-1],corners[-1],corners[-nx]])\n",
    "    src = np.float32([[src_top_left,src_top_right,src_bottom_right,src_bottom_left]])\n",
    "    print('Source points :' , src)\n",
    "    print('Image shape : ',img.shape)\n",
    "    dst_points = np.float32([[destination_top_left,destination_top_right,destination_bottom_right,destination_bottom_left]])\n",
    "    \n",
    "    #set 2\n",
    "    src = np.float32([[(200, 720), (570, 470), (720, 470), (1130, 720)]])\n",
    "    dst_points = np.float32([[(350, 720), (350, 0), (980, 0), (980, 720)]])\n",
    "    \n",
    "\n",
    "    #set 3\n",
    "    #offset_x = 400 # offset for dst points\n",
    "    #offset_y = 50\n",
    "    # For source points I'm grabbing the outer four detected corners\n",
    "    #src = np.float32([[610,440], [670, 440], [1040, 680], [260, 680]])\n",
    "    # For destination points, I'm arbitrarily choosing some points to be\n",
    "    # a nice fit for displaying our warped result\n",
    "    # again, not exact, but close enough for our purposes\n",
    "    #dst_points = np.float32([[offset_x, offset_y], [img_size[0]-offset_x, offset_y],\n",
    "    #                            [img_size[0]-offset_x, img_size[1]-offset_y],\n",
    "    #                           [offset_x, img_size[1]-offset_y]])\n",
    "    \n",
    "    \n",
    "    #set 3 end\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst_points)\n",
    "    warped = cv2.warpPerspective(undis, M, (img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #delete the next two lines\n",
    "    #M = None\n",
    "    #warped = np.copy(img) \n",
    "    \n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    \n",
    "    dist_pickle = {}\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    dist_pickle[\"M\"] = M\n",
    "    #dist_pickle[\"warped\"] = warped\n",
    "    pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_pickle.p\", \"wb\" ) )\n",
    "    \n",
    "    return warped, M, undis\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_undistorted_and_warped_images(image1, image2, text1= 'Original Image', text2 = 'Undistorted and Warped Image'):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image1)\n",
    "    ax1.set_title(text1, fontsize=50)\n",
    "    ax2.imshow(image2)\n",
    "    ax2.set_title(text2, fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''img = cv2.imread('test_images/test5.jpg')\n",
    "plt.imshow(img)\n",
    "top_down, perspective_M = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(top_down)\n",
    "ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "cv2.imwrite('test_images/bird_eye_test5.jpg',top_down)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bgr_color_images(img) :\n",
    "    #grayscale image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #b,g,r image\n",
    "    b_img = img[:,:,0]\n",
    "    g_img = img[:,:,1]\n",
    "    r_img = img[:,:,2]\n",
    "\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(30, 30))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(gray,cmap='gray')\n",
    "    ax1.set_title('gray', fontsize=50)\n",
    "    ax2.imshow(b_img,cmap='gray')\n",
    "    ax2.set_title('b_img', fontsize=50)\n",
    "    ax3.imshow(g_img,cmap='gray')\n",
    "    ax3.set_title('g_img', fontsize=50)\n",
    "    ax4.imshow(r_img,cmap='gray')\n",
    "    ax4.set_title('r_img', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hls_color_images(img) :\n",
    "    #RGB to HLS\n",
    "    hls_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    h_img = hls_image[:,:,0]\n",
    "    l_img = hls_image[:,:,1]\n",
    "    s_img = hls_image[:,:,2]\n",
    "\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(30, 30))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(hls_image)\n",
    "    ax1.set_title('hls_image', fontsize=50)\n",
    "    ax2.imshow(h_img,cmap='gray')\n",
    "    ax2.set_title('h_img', fontsize=50)\n",
    "    ax3.imshow(l_img,cmap='gray')\n",
    "    ax3.set_title('l_img', fontsize=50)\n",
    "    ax4.imshow(s_img,cmap='gray')\n",
    "    ax4.set_title('s_img', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSV Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hsv_color_images(img) :\n",
    "\n",
    "    #RGB to HLS\n",
    "    hsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hsv_h_img = hsv_image[:,:,0]\n",
    "    hsv_s_img = hsv_image[:,:,1]\n",
    "    hsv_v_img = hsv_image[:,:,2]\n",
    "\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(30, 30))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(hsv_image)\n",
    "    ax1.set_title('hsv_image', fontsize=50)\n",
    "    ax2.imshow(hsv_h_img,cmap='gray')\n",
    "    ax2.set_title('hsv_h_img', fontsize=50)\n",
    "    ax3.imshow(hsv_s_img,cmap='gray')\n",
    "    ax3.set_title('hsv_s_img', fontsize=50)\n",
    "    ax4.imshow(hsv_v_img,cmap='gray')\n",
    "    ax4.set_title('hsv_v_img', fontsize=50)\n",
    "'''    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    fig = plt.figure(1, (30, 30))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(1, 4),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.2,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    grid[0].imshow(hsv_image)\n",
    "    grid[1].imshow(hsv_h_img, cmap = 'gray')\n",
    "    grid[2].imshow(hsv_s_img,  cmap = 'gray')\n",
    "    grid[3].imshow(hsv_v_img,  cmap = 'gray')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold functions for sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x' :\n",
    "        sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0)\n",
    "    else :\n",
    "        sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1)\n",
    "    # 3) Take the absolute value of the derivative or gradient  \n",
    "    if orient == 'x' :\n",
    "        absSobel = abs(sobelx)\n",
    "    else :\n",
    "        absSobel = abs(sobely)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*absSobel/(np.max(absSobel)))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    masked_output = np.zeros_like(scaled_sobel)        \n",
    "    masked_output [(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1   \n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = np.copy(masked_output) # Remove this line\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    # 3) Calculate the magnitude \n",
    "    mag = np.sqrt(sobelx*sobelx+sobely*sobely)\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*mag/(np.max(mag)))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    masked_sobel = np.zeros_like(scaled_sobel)\n",
    "    masked_sobel[ (scaled_sobel>=mag_thresh[0]) & (scaled_sobel<= mag_thresh[1]) ] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = np.copy(masked_sobel) # Remove this line\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    direction_gradient = np.arctan2(abs_sobely,abs_sobelx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    masked_sobel = np.zeros_like(direction_gradient)\n",
    "    masked_sobel[ (direction_gradient >= thresh[0]) & (direction_gradient <= thresh[1]) ] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return masked_sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_4_images(img1,img2,img3,img4,txt1,txt2,txt3,txt4):\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(30, 30))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1,cmap='gray')\n",
    "    ax1.set_title(txt1, fontsize=50)\n",
    "    ax2.imshow(img2,cmap='gray')\n",
    "    ax2.set_title(txt2, fontsize=50)\n",
    "    ax3.imshow(img3,cmap='gray')\n",
    "    ax3.set_title(txt3, fontsize=50)\n",
    "    ax4.imshow(img4,cmap='gray')\n",
    "    ax4.set_title(txt4, fontsize=50)\n",
    "    \n",
    "def print_2_images (img1,img2,txt1='',txt2=''):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 30))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1,cmap='gray')\n",
    "    ax1.set_title(txt1, fontsize=50)\n",
    "    ax2.imshow(img2,cmap='gray')\n",
    "    ax2.set_title(txt2, fontsize=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''mtx,dist_coeff = carmera_parameters()\n",
    "top_down, perspective_M = corners_unwarp(img, nx, ny, mtx, dist_coeff)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nx = 9\n",
    "ny = 6\n",
    "img = cv2.imread('test_images/test5.jpg')\n",
    "ksize = 3\n",
    "bird_eye_view_image = []\n",
    "def process_the_image(img):\n",
    "    #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    mtx,dist_coeff = carmera_parameters()\n",
    "    top_down, perspective_M, undist = corners_unwarp(img, nx, ny, mtx, dist_coeff)\n",
    "    \n",
    "    print_undistorted_and_warped_images(cv2.cvtColor(img,cv2.COLOR_BGR2RGB),cv2.cvtColor(top_down,cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    cv2.imwrite('test_images/bird_eye_test5.jpg',top_down)\n",
    "    \n",
    "    bird_eye_view_image = np.copy(top_down)\n",
    "    \n",
    "    print_bgr_color_images(bird_eye_view_image)\n",
    "    print_hls_color_images(bird_eye_view_image)\n",
    "    print_hsv_color_images(bird_eye_view_image)\n",
    "    \n",
    "    gradx = abs_sobel_thresh(bird_eye_view_image, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    grady = abs_sobel_thresh(bird_eye_view_image, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(bird_eye_view_image, sobel_kernel=ksize, mag_thresh=(20, 100))\n",
    "    dir_binary = dir_threshold(bird_eye_view_image, sobel_kernel=ksize, thresh=(0, 0.2))\n",
    "    print_4_images(gradx,grady,mag_binary,dir_binary,'Gradient x','Gradient y','mag_binary','dir_binary')\n",
    "    \n",
    "    #Combined threshols sobel\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    #==========================================================#\n",
    "    combined_2 = np.zeros_like(dir_binary)\n",
    "    combined_2[((gradx == 1) & (grady == 1)) | ((mag_binary == 1))] = 1\n",
    "    #==========================================================#\n",
    "    print_2_images(combined,combined_2,'Combined 1','Combined 2')\n",
    "    #==========================================================#\n",
    "    \n",
    "    \n",
    "    #Color thresholding\n",
    "    #=======================================================#\n",
    "    r_img = bird_eye_view_image[:,:,2]\n",
    "    \n",
    "    thresh = (200, 255)\n",
    "    binary_red = np.zeros_like(r_img)\n",
    "    binary_red[(r_img > thresh[0]) & (r_img <= thresh[1])] = 1\n",
    "    #=======================================================#\n",
    "    #=======================================================#\n",
    "    hls_image = cv2.cvtColor(bird_eye_view_image, cv2.COLOR_BGR2HLS)\n",
    "    s_img = hls_image[:,:,2]\n",
    "    \n",
    "    thresh = (90, 255)\n",
    "    binary_s_hls = np.zeros_like(s_img)\n",
    "    binary_s_hls[(s_img > thresh[0]) & (s_img <= thresh[1])] = 1\n",
    "    #=======================================================#\n",
    "    print_2_images(binary_red,binary_s_hls,'binary_red','binary_s_hls')\n",
    "    #==========================================================#\n",
    "    \n",
    "    \n",
    "    combined_try1 = np.zeros_like(mag_binary)\n",
    "    combined_try1[((gradx == 1) & (grady == 1)) | ((mag_binary == 1)) | (binary_red==1) & (binary_s_hls==1)] = 1\n",
    "    plt.figure()\n",
    "    plt.imshow(combined_try1,cmap='gray')\n",
    "    \n",
    "    return combined_try1, bird_eye_view_image, undist\n",
    "processed_image, bird_eye_view_image, undist = process_the_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import numpy as np\n",
    "histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "plt.plot(histogram)Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = np.sum(processed_image[processed_image.shape[0]//2:,:], axis=0)\n",
    "plt.plot(histogram,linewidth=2.5,color='yellow')\n",
    "out_img = np.dstack((processed_image, processed_image, processed_image))*255\n",
    "plt.imshow(out_img)\n",
    "\n",
    "\n",
    "count = 0\n",
    "left_fitx = 0\n",
    "right_fitx = 0\n",
    "left_fit = 0\n",
    "right_fit = 0\n",
    "\n",
    "#set 2\n",
    "src = np.float32([[(200, 720), (570, 470), (720, 470), (1130, 720)]])\n",
    "dst_points = np.float32([[(350, 720), (350, 0), (980, 0), (980, 720)]])\n",
    "Minv = cv2.getPerspectiveTransform(dst_points, src)\n",
    "image = cv2.imread('test_images/test3.jpg')\n",
    "\n",
    "print(Minv)\n",
    "plt.figure()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the starting point of the lane lines. Once we get the starting point of the lane lines we can skip the sliding window part for the next frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_line(count,left_fitx, left_fit, right_fit, Minv, bird_eye_view_image, undist) :\n",
    "    \n",
    "    if count==0 :\n",
    "        # Create an output image to draw on and  visualize the result\n",
    "        out_img = np.dstack((processed_image, processed_image, processed_image))*255\n",
    "        plt.imshow(out_img)\n",
    "        print(\"out_img :\", out_img.shape)\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set height of windows\n",
    "        window_height = np.int(processed_image.shape[0]/nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = processed_image.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 100\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = processed_image.shape[0] - (window+1)*window_height\n",
    "            win_y_high = processed_image.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "            (0,255,0), 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "            (0,255,0), 2) \n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "\n",
    "        print(leftx_current)\n",
    "        print(rightx_current)\n",
    "\n",
    "        print(left_lane_inds)\n",
    "        print(right_lane_inds)\n",
    "\n",
    "        print(len(left_lane_inds))\n",
    "        print(len(right_lane_inds))\n",
    "\n",
    "\n",
    "\n",
    "        #=====================================================#\n",
    "        ploty = np.linspace(0, processed_image.shape[0]-1, processed_image.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        plt.figure()\n",
    "        plt.imshow(out_img)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "\n",
    "    else :\n",
    "        #===================================================#\n",
    "        # Assume you now have a new warped binary image \n",
    "        # from the next frame of video (also called \"binary_warped\")\n",
    "        # It's now much easier to find line pixels!\n",
    "        nonzero = processed_image.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        margin = 100\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "        left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "        left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "        right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "        right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, processed_image.shape[0]-1, processed_image.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        #=======================================================#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((processed_image, processed_image, processed_image))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        # Color in left and right line pixels\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                      ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                      ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        plt.figure()\n",
    "        plt.imshow(result)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(processed_image).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    print(\"color warp shape\", color_warp.shape)\n",
    "    print(\"warp zero shape\", warp_zero.shape)\n",
    "    print(type(color_warp))\n",
    "    plt.figure()\n",
    "    #plt.imshow(color_warp)\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    plt.imshow(result)\n",
    "    return left_fitx, left_fit, right_fit\n",
    "\n",
    "\n",
    "\n",
    "left_fitx, left_fit, right_fit = lane_line(count, left_fitx, left_fit, right_fit, Minv, bird_eye_view_image, undist)\n",
    "count= count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'test_videos_output/project_video.mp4'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
