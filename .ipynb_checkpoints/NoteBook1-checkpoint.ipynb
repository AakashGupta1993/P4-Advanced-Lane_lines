{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "i = 0\n",
    "fig = plt.figure(1, (30, 30))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(7, 3),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.2,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "\n",
    "print(\"Total images :\" , len(images))\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)    \n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        ax = grid[i]\n",
    "        ax.imshow(img)\n",
    "        i = i +1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "#print(ret)\n",
    "#print(corners)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above cell ran sucessfully, you should now have objpoints and imgpoints needed for camera calibration. Run the cell below to calibrate, calculate distortion coefficients, and test undistortion on an image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = cv2.imread('camera_cal/test_image.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('camera_cal/test_undist.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_pickle.p\", \"wb\" ) )\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#import cv2\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "\n",
    "# Read in the saved camera matrix and distortion coefficients\n",
    "# These are the arrays you calculated using cv2.calibrateCamera()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/wide_dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Read in an image\n",
    "img = cv2.imread('test_images/straight_lines1.jpg')\n",
    "nx = 9 # the number of inside corners in x\n",
    "ny = 6 # the number of inside corners in y\n",
    "\n",
    "# MODIFY THIS FUNCTION TO GENERATE OUTPUT \n",
    "# THAT LOOKS LIKE THE IMAGE ABOVE\n",
    "\n",
    "print(dist)\n",
    "plt.imshow(img)\n",
    "\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "\n",
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    # 1) Undistort using mtx and dist.\n",
    "    undis = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # 2) Convert to grayscale\n",
    "    plt.figure()\n",
    "    plt.imshow(undis)\n",
    "    \n",
    "    gray = cv2.cvtColor(undis, cv2.COLOR_BGR2GRAY)\n",
    "    # 3) Find the chessboard corners\n",
    "    offset=10\n",
    "    \n",
    "    src_bottom_left = [260,680]\n",
    "    src_bottom_right = [1040,680]\n",
    "    src_top_left = [581,460]\n",
    "    src_top_right = [700,460]\n",
    "    \n",
    "    destination_bottom_left = [100,700]\n",
    "    destination_bottom_right = [1000,700]\n",
    "    destination_top_left = [100,50]\n",
    "    destination_top_right = [1000,50]\n",
    "    \n",
    "    #src = np.float32([corners[0],corners[nx-1],corners[-1],corners[-nx]])\n",
    "    src = np.float32([[src_top_left,src_top_right,src_bottom_right,src_bottom_left]])\n",
    "    print(src)\n",
    "    print(img.shape)\n",
    "    dst_points = np.float32([[destination_top_left,destination_top_right,destination_bottom_right,destination_bottom_left]])\n",
    "    #dst_points = np.float32([[offset,offset],\n",
    "    #                [img.shape[1]-offset,offset],\n",
    "    #                [img.shape[1]-offset,img.shape[0]-offset],\n",
    "    #                [offset,img.shape[0]-offset]])\n",
    "    #dst_points = np.float32([(offset,offset),(1200-offset,offset),()])\n",
    "    M = cv2.getPerspectiveTransform(src, dst_points)\n",
    "    warped = cv2.warpPerspective(undis, M, (img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #delete the next two lines\n",
    "    #M = None\n",
    "    #warped = np.copy(img) \n",
    "    return warped, M\n",
    "\n",
    "top_down, perspective_M = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(top_down)\n",
    "ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
